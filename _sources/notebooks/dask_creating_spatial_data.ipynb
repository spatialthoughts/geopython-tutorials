{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Creating Spatial Data\n",
        "\n",
        "A common operation in spatial analysis is to take non-spatial data, such as CSV files, and creating a spatial dataset from it using coordinate information contained in the file. GeoPandas provides a convenient way to take data from a delimited-text file, create geometry and write the results as a spatial dataset.\n",
        "\n",
        "The source data comes from [GeoNames](http://www.geonames.org/) - a free and open database of geographic names of the world. It is a huge database containing millions of records per country. The data is distributed as country-level text files in a tab-delimited format. \n",
        "\n",
        "We will be using the [dask dataframes](https://docs.dask.org/en/stable/) which enables us to work in the parallel computing in python which does faster computation and allows to work with clusters of thousands of cores.  \n",
        "\n",
        "We will read a tab-delimited file of places in dask environment, filter it to a feature class, create a GeoDataFrame and export it as a GeoPackage file.\n",
        "\n",
        "Input Layers:\n",
        "\n",
        "* `CA.zip`: Geographical database of Canada.\n",
        "* `MX.zip`: Geographical database of Mexico.\n",
        "* `US.zip`: Geographical database of United States.\n",
        "\n",
        "Output Layers:\n",
        "\n",
        "*   `mountains.gpkg` : A GeoPackage containing a vector layer of mountains locations in North America.\n",
        "\n",
        "\n",
        "Data Credit:\n",
        "\n",
        "*   [Geonames](http://www.geonames.org/). Retrieved 2022-09"
      ],
      "metadata": {
        "id": "mhym8ESj0-17"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup and Data Download\n",
        "\n",
        "The following blocks of code will install the required packages and download the datasets to your Colab environment."
      ],
      "metadata": {
        "id": "Vv0RpBAO_AZn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LnESLhL3nm-L"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "if 'google.colab' in str(get_ipython()):\n",
        "    !pip install --quiet dask_geopandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e9qg9lvmVgxV"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import dask.dataframe as dd\n",
        "import dask_geopandas as dg\n",
        "import geopandas as gpd\n",
        "import zipfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DtZvWFlBVuZP"
      },
      "outputs": [],
      "source": [
        "data_folder = 'data'\n",
        "output_folder = 'output'\n",
        "\n",
        "if not os.path.exists(data_folder):\n",
        "    os.mkdir(data_folder)\n",
        "if not os.path.exists(output_folder):\n",
        "    os.mkdir(output_folder)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def download(url):\n",
        "    filename = os.path.join(data_folder, os.path.basename(url))\n",
        "    if not os.path.exists(filename):\n",
        "        from urllib.request import urlretrieve\n",
        "        local, _ = urlretrieve(url, filename)\n",
        "        print('Downloaded ' + local)\n",
        "\n",
        "countries = ['US', 'MX', 'CA']\n",
        "\n",
        "download_url = 'https://download.geonames.org/export/dump/'\n",
        "\n",
        "for country in countries:\n",
        "  download(download_url + country + '.zip')"
      ],
      "metadata": {
        "id": "P27F-4yNFDzl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for country in countries:\n",
        "  zip_file_path = os.path.join(data_folder, country + '.zip')\n",
        "  with zipfile.ZipFile(zip_file_path) as f:\n",
        "    f.extractall(data_folder)"
      ],
      "metadata": {
        "id": "xzhCCjQSEksY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Pre-Processing"
      ],
      "metadata": {
        "id": "S3zu9jt_HIDY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The files do not contain a header row with column names, so we need to specify them when reading the data. The data format is described in detail on the [Data Export]('https://www.geonames.org/export/') page.\n",
        "We will be also specifying the data type of the column names."
      ],
      "metadata": {
        "id": "edQi9LZJ_JZ9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xq6mTdFMTVwP"
      },
      "outputs": [],
      "source": [
        "column_names = [\n",
        "    'geonameid', 'name', 'asciiname', 'alternatenames', \n",
        "    'latitude', 'longitude', 'feature class', 'feature code',\n",
        "    'country code', 'cc2', 'admin1 code', 'admin2 code',\n",
        "    'admin3 code', 'admin4 code', 'population', 'elevation',\n",
        "    'dem', 'timezone', 'modification date'\n",
        "]\n",
        "\n",
        "dtypes = {'geonameid':int , 'name':object , 'asciiname':object, 'alternatenames':object, \n",
        "    'latitude':float, 'longitude':float, 'feature class':object, 'feature code':object,\n",
        "    'country code':object, 'cc2':object, 'admin1 code':object, 'admin2 code':object,\n",
        "    'admin3 code':object, 'admin4 code':object, 'population':int, 'elevation':float,\n",
        "    'dem':int, 'timezone':object, 'modification date':object}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We specify the separator as \\t (tab) as an argument to the read_csv() method in dask dataframe."
      ],
      "metadata": {
        "id": "o6NCbijJExRP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MvkhY0bnXe2o"
      },
      "outputs": [],
      "source": [
        "dd_list = []\n",
        "for country in countries:\n",
        "  country_txt = os.path.join(data_folder, country + '.txt')\n",
        "  country_data = dd.read_csv(country_txt, sep = '\\t', names = column_names, dtype=dtypes) \n",
        "  dd_list.append(country_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Merging and Creating Spatial Data"
      ],
      "metadata": {
        "id": "K2X1TmWpHNL9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will now concat all the dataframes in one dataframe."
      ],
      "metadata": {
        "id": "LyJVPnN-FYvP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VuRDPbzAPhcQ"
      },
      "outputs": [],
      "source": [
        "merged_dd = dd.concat(dd_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The input data as a column `feature_class` categorizing the place into [9 feature classes](https://www.geonames.org/export/codes.html). We can select all rows with the value `T` with the category *mountain,hill,rockâ€¦*"
      ],
      "metadata": {
        "id": "kj43GvKyF6fo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bfaGuPAWY5no"
      },
      "outputs": [],
      "source": [
        "mountain_dd = merged_dd[merged_dd['feature class']== 'T']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GeoPandas has a conveinent function `points_from_xy()` that creates a Geometry column from X and Y coordinates. We can then take a dask dataframe and create a dask goDataFrame by specifying a *CRS* and the *geometry* column."
      ],
      "metadata": {
        "id": "oVGrfGPYGjxA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mountain_dd['geometry'] = dg.points_from_xy(mountain_dd, 'longitude', 'latitude', crs = 'EPSG:4326')"
      ],
      "metadata": {
        "id": "5Mz2eBqxbtpV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converting the dask dataframe to dask geodatafeame by using the `from_dask_dataframe` function and then converting this lazy Dask collection into its in-memory equivalent i.e. Geodataframe by using the `compute` function."
      ],
      "metadata": {
        "id": "iG-Qkv4uIKsR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mountain_df = dg.from_dask_dataframe(mountain_dd).compute()"
      ],
      "metadata": {
        "id": "PMUUC6OKHuNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mountain_df"
      ],
      "metadata": {
        "id": "q5zT0VF9IijK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can write the resulting GeoDataFrame to a new GeoPackage file."
      ],
      "metadata": {
        "id": "vTfgVq39JPSM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_filename = 'mountains.gpkg'\n",
        "output_path = os.path.join(output_folder, output_filename)\n",
        "\n",
        "mountain_df.to_file(driver='GPKG', filename = output_path, layer = 'mountains',  encoding='utf-8')\n",
        "print('Successfully written output file at {}'.format(output_path))"
      ],
      "metadata": {
        "id": "fx8SCzAumJyq"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}